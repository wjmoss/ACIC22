{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c789e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from lightgbm import LGBMRegressor,LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7382511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pd.read_csv(\"./data/practice/acic_practice_0001.csv\")\n",
    "data_y = pd.read_csv(\"./data/practice_year/acic_practice_year_0001.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5349366",
   "metadata": {},
   "source": [
    "# propensity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5246ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t = pd.merge(data_x, data_y[['id.practice','Z']].drop_duplicates(), on='id.practice')\n",
    "df = data_t\n",
    "ct = ['X2','X4']\n",
    "for c in ct:\n",
    "    df[c] = df[c].astype('category')\n",
    "\n",
    "debias_m = LGBMClassifier(max_depth=3)\n",
    "\n",
    "X = ['X1','X2','X3','X4','X5','X6','X7','X8','X9']\n",
    "T = ['Z']\n",
    "ps_res =  df[T] - cross_val_predict(debias_m, df[X], df[T].values.ravel(), cv=5, method='predict_proba')[:,1].reshape(-1,1) + df[T].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66be44",
   "metadata": {},
   "source": [
    "### (1) 调整max_depth 和 num_leaves\n",
    "确定树的大小及复杂度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a50a5b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数的最佳取值:{'max_depth': 4, 'num_leaves': 20}\n",
      "最佳模型得分:0.8248431855500822\n",
      "[0.82484319 0.82484319 0.82484319 0.82257143 0.82257143 0.82257143\n",
      " 0.81984072 0.81984072 0.81984072]\n",
      "[{'max_depth': 4, 'num_leaves': 20}, {'max_depth': 4, 'num_leaves': 30}, {'max_depth': 4, 'num_leaves': 40}, {'max_depth': 6, 'num_leaves': 20}, {'max_depth': 6, 'num_leaves': 30}, {'max_depth': 6, 'num_leaves': 40}, {'max_depth': 8, 'num_leaves': 20}, {'max_depth': 8, 'num_leaves': 30}, {'max_depth': 8, 'num_leaves': 40}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'max_depth': [4,6,8],\n",
    "    'num_leaves': [20,30,40],\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         max_depth = 6,\n",
    "                         num_leaves = 40,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=21,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.001,\n",
    "                         reg_lambda = 8,\n",
    "                         cat_smooth = 0,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=10)\n",
    "gsearch.fit(df[X], df[T].values.ravel())\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487d901f",
   "metadata": {},
   "source": [
    "### (2) 调整min_data_in_leaf 和 min_sum_hessian_in_leaf\n",
    "防止树过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f385fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数的最佳取值:{'reg_alpha': 0.002, 'reg_lambda': 10}\n",
      "最佳模型得分:0.8294532019704434\n",
      "[0.8225     0.82811494 0.8243087  0.82628654 0.82663218 0.82482841\n",
      " 0.82746552 0.82484319 0.8279532  0.82827422 0.82318637 0.82697291\n",
      " 0.82634072 0.82629146 0.82911987 0.82451232 0.82746305 0.82816174\n",
      " 0.8274532  0.8294532 ]\n",
      "[{'reg_alpha': 0.0005, 'reg_lambda': 6}, {'reg_alpha': 0.0005, 'reg_lambda': 7}, {'reg_alpha': 0.0005, 'reg_lambda': 8}, {'reg_alpha': 0.0005, 'reg_lambda': 9}, {'reg_alpha': 0.0005, 'reg_lambda': 10}, {'reg_alpha': 0.001, 'reg_lambda': 6}, {'reg_alpha': 0.001, 'reg_lambda': 7}, {'reg_alpha': 0.001, 'reg_lambda': 8}, {'reg_alpha': 0.001, 'reg_lambda': 9}, {'reg_alpha': 0.001, 'reg_lambda': 10}, {'reg_alpha': 0.0015, 'reg_lambda': 6}, {'reg_alpha': 0.0015, 'reg_lambda': 7}, {'reg_alpha': 0.0015, 'reg_lambda': 8}, {'reg_alpha': 0.0015, 'reg_lambda': 9}, {'reg_alpha': 0.0015, 'reg_lambda': 10}, {'reg_alpha': 0.002, 'reg_lambda': 6}, {'reg_alpha': 0.002, 'reg_lambda': 7}, {'reg_alpha': 0.002, 'reg_lambda': 8}, {'reg_alpha': 0.002, 'reg_lambda': 9}, {'reg_alpha': 0.002, 'reg_lambda': 10}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    #'min_child_samples': [18,19,20,21,22],\n",
    "    #'min_child_weight': [0.001,0.002],\n",
    "    'reg_alpha': [0.0005, 0.001, 0.0015, 0.002],\n",
    "    'reg_lambda': [6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         max_depth = 4,\n",
    "                         num_leaves = 20,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=21,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.0005,\n",
    "                         reg_lambda = 8,\n",
    "                         cat_smooth = 0,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=10)\n",
    "gsearch.fit(df[X], df[T].values.ravel())\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99dee8",
   "metadata": {},
   "source": [
    "### (3) 调整lambda_l1(reg_alpha)和lambda_l2(reg_lambda)\n",
    "通过L1正则化和L2正则化降低过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f03c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数的最佳取值:{'reg_alpha': 0.0015, 'reg_lambda': 10}\n",
      "最佳模型得分:0.82911986863711\n",
      "[0.8225     0.82811494 0.8243087  0.82628654 0.82663218 0.82482841\n",
      " 0.82746552 0.82484319 0.8279532  0.82827422 0.82318637 0.82697291\n",
      " 0.82634072 0.82629146 0.82911987 0.82216667 0.82611248 0.82697537\n",
      " 0.82826929 0.82662726]\n",
      "[{'reg_alpha': 0.0005, 'reg_lambda': 6}, {'reg_alpha': 0.0005, 'reg_lambda': 7}, {'reg_alpha': 0.0005, 'reg_lambda': 8}, {'reg_alpha': 0.0005, 'reg_lambda': 9}, {'reg_alpha': 0.0005, 'reg_lambda': 10}, {'reg_alpha': 0.001, 'reg_lambda': 6}, {'reg_alpha': 0.001, 'reg_lambda': 7}, {'reg_alpha': 0.001, 'reg_lambda': 8}, {'reg_alpha': 0.001, 'reg_lambda': 9}, {'reg_alpha': 0.001, 'reg_lambda': 10}, {'reg_alpha': 0.0015, 'reg_lambda': 6}, {'reg_alpha': 0.0015, 'reg_lambda': 7}, {'reg_alpha': 0.0015, 'reg_lambda': 8}, {'reg_alpha': 0.0015, 'reg_lambda': 9}, {'reg_alpha': 0.0015, 'reg_lambda': 10}, {'reg_alpha': 0.0002, 'reg_lambda': 6}, {'reg_alpha': 0.0002, 'reg_lambda': 7}, {'reg_alpha': 0.0002, 'reg_lambda': 8}, {'reg_alpha': 0.0002, 'reg_lambda': 9}, {'reg_alpha': 0.0002, 'reg_lambda': 10}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'reg_alpha': [0.0005, 0.001, 0.0015, 0.0002],\n",
    "    'reg_lambda': [6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         max_depth = 4,\n",
    "                         num_leaves = 20,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=21,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.001,\n",
    "                         reg_lambda = 8,\n",
    "                         cat_smooth = 10,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=10)\n",
    "gsearch.fit(df[X], df[T].values.ravel())\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77121c",
   "metadata": {},
   "source": [
    "### (4) 调整cat_smooth\n",
    "cat_smooth为设置每个类别拥有最小的个数，主要用于去噪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0934bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数的最佳取值:{'cat_smooth': 0}\n",
      "最佳模型得分:0.8254433497536946\n",
      "[0.82544335 0.82544335 0.82544335]\n",
      "[{'cat_smooth': 0}, {'cat_smooth': 10}, {'cat_smooth': 20}]\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'cat_smooth': [0,10,20],\n",
    "}\n",
    "\n",
    "model = LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         max_depth = 4,\n",
    "                         num_leaves = 20,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=19,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.002,\n",
    "                         reg_lambda = 10,\n",
    "                         cat_smooth = 0,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=10)\n",
    "gsearch.fit(df[X], df[T].values.ravel())\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad9ae3",
   "metadata": {},
   "source": [
    "## fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad7b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "debias_m = LGBMClassifier(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'binary_logloss,auc',\n",
    "                         max_depth = 4,\n",
    "                         num_leaves = 20,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=21,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.002,\n",
    "                         reg_lambda = 10,\n",
    "                         cat_smooth = 0,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "\n",
    "ps = cross_val_predict(debias_m, df[X], df[T].values.ravel(), cv=10, method='predict_proba')[:,1]\n",
    "#ps_res =  df[T] - cross_val_predict(debias_m, df[X], df[T].values.ravel(), cv=5, method='predict_proba')[:,1].reshape(-1,1) + df[T].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2308bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = cross_val_predict(debias_m, df[X], df[T].values.ravel(), cv=5, method='predict_proba')[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fd32f858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 235, 61, 52)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp=df.assign(propensity_score=ps)\n",
    "tp = sum((tmp['propensity_score'] >= 0.5) & (tmp['Z']==1))\n",
    "tn = sum((tmp['propensity_score'] < 0.5) & (tmp['Z']==0))\n",
    "fp = sum((tmp['propensity_score'] >= 0.5) & (tmp['Z']==0))\n",
    "fn =sum((tmp['propensity_score'] < 0.5) & (tmp['Z']==1))\n",
    "tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf2c811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id.practice      int64\n",
       "X1               int64\n",
       "X3               int64\n",
       "X5               int64\n",
       "X6             float64\n",
       "X7             float64\n",
       "X8             float64\n",
       "X9             float64\n",
       "Z                int64\n",
       "X2_A             uint8\n",
       "X2_B             uint8\n",
       "X2_C             uint8\n",
       "X4_A             uint8\n",
       "X4_B             uint8\n",
       "X4_C             uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "df = pd.get_dummies(data_t, columns=['X2','X4'])\n",
    "X = ['X1','X2_A','X2_B','X2_C','X3','X4_A','X4_B','X4_C','X5','X6','X7','X8','X9']\n",
    "T = ['Z']\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09b128a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['X6','X7','X8','X9']] = scaler.fit_transform(df[['X6','X7','X8','X9']]) / 2\n",
    "ps_model = LogisticRegression(C=1e6, max_iter=1000).fit(df[X], df[T].values.ravel())\n",
    "#ps_model = MLPClassifier(hidden_layer_sizes=(50,), solver='lbfgs', random_state=1, max_iter=500, learning_rate='invscaling').fit(df[X], df[T].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72092848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e5940c89ecaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpropensity_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mps_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'propensity_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'propensity_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'propensity_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'propensity_score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ps_model' is not defined"
     ]
    }
   ],
   "source": [
    "tmp=df.assign(propensity_score=ps_model.predict_proba(df[X])[:, 1])\n",
    "tp = sum((tmp['propensity_score'] >= 0.5) & (tmp['Z']==1))\n",
    "tn = sum((tmp['propensity_score'] < 0.5) & (tmp['Z']==0))\n",
    "fp = sum((tmp['propensity_score'] >= 0.5) & (tmp['Z']==0))\n",
    "fn =sum((tmp['propensity_score'] < 0.5) & (tmp['Z']==1))\n",
    "tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d7ffc",
   "metadata": {},
   "source": [
    "# average outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fca31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_o = pd.merge(data_x, data_y, on='id.practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef706f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data_o, columns=['X2','X4'])\n",
    "XV = df.columns.drop(['id.practice','post','Z','n.patients'])\n",
    "Y = ['Y']\n",
    "ao_model = MLPRegressor(hidden_layer_sizes=(50,), solver='lbfgs', alpha=0.1, random_state=1, max_iter=1000, learning_rate='invscaling', early_stopping=True).fit(df[XV], df[Y].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66d04407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>year</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>post</th>\n",
       "      <th>n.patients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>20.774076</td>\n",
       "      <td>14.153255</td>\n",
       "      <td>0.161126</td>\n",
       "      <td>43.431874</td>\n",
       "      <td>1</td>\n",
       "      <td>1025.523263</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>20.774076</td>\n",
       "      <td>14.153255</td>\n",
       "      <td>0.161126</td>\n",
       "      <td>43.431874</td>\n",
       "      <td>2</td>\n",
       "      <td>1613.777568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>20.774076</td>\n",
       "      <td>14.153255</td>\n",
       "      <td>0.161126</td>\n",
       "      <td>43.431874</td>\n",
       "      <td>3</td>\n",
       "      <td>1189.200788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>20.774076</td>\n",
       "      <td>14.153255</td>\n",
       "      <td>0.161126</td>\n",
       "      <td>43.431874</td>\n",
       "      <td>4</td>\n",
       "      <td>1619.829704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>33.565928</td>\n",
       "      <td>3.284657</td>\n",
       "      <td>0.556784</td>\n",
       "      <td>12.721988</td>\n",
       "      <td>1</td>\n",
       "      <td>834.169421</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1 X2  X3 X4  X5         X6         X7        X8         X9  year  \\\n",
       "0   0  A   1  A   1  20.774076  14.153255  0.161126  43.431874     1   \n",
       "1   0  A   1  A   1  20.774076  14.153255  0.161126  43.431874     2   \n",
       "2   0  A   1  A   1  20.774076  14.153255  0.161126  43.431874     3   \n",
       "3   0  A   1  A   1  20.774076  14.153255  0.161126  43.431874     4   \n",
       "4   0  A   0  C   0  33.565928   3.284657  0.556784  12.721988     1   \n",
       "\n",
       "             Y  Z  post  n.patients  \n",
       "0  1025.523263  1     0         113  \n",
       "1  1613.777568  1     0         109  \n",
       "2  1189.200788  1     1         121  \n",
       "3  1619.829704  1     1         131  \n",
       "4   834.169421  1     0         264  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_o.iloc[:,1:15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "580f9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_o\n",
    "ct = ['X2','X4']\n",
    "for c in ct:\n",
    "    df[c] = df[c].astype('category')\n",
    "    \n",
    "XV = df.columns.drop(['id.practice','year','post','Z','n.patients'])\n",
    "Y = ['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb228853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870.6451336763548\n",
      "1010.0760840822331\n",
      "1134.3928342316492\n",
      "1250.6285559851644\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(df[(df['year']==i) & (df['Z']==0)]['Y'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8d73df77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoise_m = LGBMRegressor(max_depth = 6)\n",
    "denoise_m.fit(df[XV], df[T], sample_weight=df['n.patients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66837b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': [4,6,8],\n",
    "    'num_leaves': [20,30,40],\n",
    "}\n",
    "\n",
    "model = LGBMRegressor(objective = 'binary',\n",
    "                         is_unbalance = True,\n",
    "                         #metric = 'log_loss',\n",
    "                         metric = 'neg_mean_squared_error',\n",
    "                         max_depth = 6,\n",
    "                         num_leaves = 40,\n",
    "                         learning_rate = 0.1,\n",
    "                         #feature_fraction = 0.7,\n",
    "                         min_child_samples=21,\n",
    "                         min_child_weight=0.001,\n",
    "                         #bagging = 1,\n",
    "                         #subsample_freq = 2,\n",
    "                         reg_alpha = 0.001,\n",
    "                         reg_lambda = 8,\n",
    "                         cat_smooth = 0,\n",
    "                         n_estimators = 200,   \n",
    "                        )\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='neg_mean_squared_error', cv=10)\n",
    "gsearch.fit(df[X], df[T], weight=df['n.patients'])\n",
    "print('参数的最佳取值:{0}'.format(gsearch.best_params_))\n",
    "print('最佳模型得分:{0}'.format(gsearch.best_score_))\n",
    "print(gsearch.cv_results_['mean_test_score'])\n",
    "print(gsearch.cv_results_['params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
